{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv', dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.loc[:,df.columns != 'label'].values/255 #normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prate\\AppData\\Local\\conda\\conda\\envs\\mlenv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "features_train, features_val, labels_train, labels_val = train_test_split(features, labels , train_size=.90, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = torch.from_numpy(features_train)\n",
    "labels_train = torch.from_numpy(labels_train).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_val = torch.from_numpy(features_val)\n",
    "labels_val = torch.from_numpy(labels_val).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset  = TensorDataset(features_train, labels_train)\n",
    "valset = TensorDataset(features_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset,  batch_size=5, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(train_loader)\n",
    "data.next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-ffdab1b9dd8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "len(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2958783a898>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADjlJREFUeJzt3X2MXOV1x/Hf8Wa9BsduWSU2izExpC4KpamJtusmjhJX1AlUqAZVoXGl1JGiblDiKqnSNghVCq3SlDYkJFJb6AIOjspLaBPADQgCblXXAlzWFDB0y0uIix0vXkdLYwOJX3ZP/9jrdDE7z4znvs36fD/SamfuuXfu0di/vTPzzL2PubsAxDOn7gYA1IPwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8I6i1V7myu9fg8za9yl0AoP9VrOuyHrJV1c4XfzC6S9HVJXZJucvdrUuvP03yttAvz7BJAwnbf0vK6bb/sN7MuSX8r6WJJ50laZ2bntft4AKqV5z3/gKQX3P1Fdz8s6Q5Ja4tpC0DZ8oR/iaTd0+7vyZa9gZkNmtmwmQ0f0aEcuwNQpDzhn+lDhTedH+zuQ+7e7+793erJsTsARcoT/j2Slk67f6akvfnaAVCVPOF/TNJyMzvbzOZK+qikzcW0BaBsbQ/1uftRM9sg6QFNDfVtdPdnCusMQKlyjfO7+32S7iuoFwAV4uu9QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRV6RTdmH3e0nd6sj7yV2ck6++4tfHxZe4Dw231hGJw5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoHKN85vZLkkHJU1IOuru/UU0heK8sv69yfr/Xvxasv5Hv/JQsn73wnuT9Ufe39Ww9vF/viK57fLPPJqsI58ivuTz6+7+owIeB0CFeNkPBJU3/C7pe2a2w8wGi2gIQDXyvuxf5e57zWyRpAfN7L/dfev0FbI/CoOSNE+n5twdgKLkOvK7+97s95ikuyQNzLDOkLv3u3t/t3ry7A5AgdoOv5nNN7MFx25L+pCkp4tqDEC58rzsXyzpLjM79ji3ufv9hXQFoHTm7pXtbKH1+kq7sLL9nSz2/sn7kvUbrvibhrUL5h5Nbts19ce7bXOavHic1GTD2kST/3v/eTh9bLri+g3J+hlffjhZPxlt9y064OMt/aMy1AcERfiBoAg/EBThB4Ii/EBQhB8IiqG+WeC7P9yRrKeG08qWZ6ivbJet/p2GtYnnX6ywk+ow1AegKcIPBEX4gaAIPxAU4QeCIvxAUIQfCIopupE08NjvJesHf3xKst7zg3kNa4fO/mly25Hf+PtkvZkl/7CvYe2llbke+qTAkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHguJ8/llg/Lu/mKyvWzbcsHbjyKrktsu+mL609+STI8l6mb5/24pkfeSDNyfr3dZ4evAPfCo9teQpd/9Hst6pOJ8fQFOEHwiK8ANBEX4gKMIPBEX4gaAIPxBU0/P5zWyjpEskjbn7+dmyXknfkrRM0i5Jl7v7K+W1GVvvJc8l6w9oYcPaWdqZ3La+q+o31/ePPcn65AfT3R+p7isss1IrR/5bJF103LIrJW1x9+WStmT3AcwiTcPv7lsljR+3eK2kTdntTZIuLbgvACVr9z3/YncflaTs96LiWgJQhdKv4Wdmg5IGJWmeTi17dwBa1O6Rf5+Z9UlS9nus0YruPuTu/e7e3630BzgAqtNu+DdLWp/dXi/pnmLaAVCVpuE3s9slPSLpXDPbY2afkHSNpDVm9rykNdl9ALNI0/f87r6uQYkT81GqsX6+g1Ymnl0gKMIPBEX4gaAIPxAU4QeCIvxAUEzRjfoM/HKy/OXLNyXrzfzxy43n4V6wY29y2/QFzU8OHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+VGbA3/2erL+4VN/nOvxH//z9zSsnbJ7dk7BXSSO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8yGXO/PnJ+g++cU7D2s5339Ls0ZPVZw6nz7o/5R7G8lM48gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUE3H+c1so6RLJI25+/nZsqsl/b6k/dlqV7n7fWU1ic6VGseXpCdXbWxYm8y573Wb/jBZP0sP59zDya2VI/8tki6aYfl17r4i+yH4wCzTNPzuvlXSeAW9AKhQnvf8G8zsKTPbaGanFdYRgEq0G/7rJb1T0gpJo5K+0mhFMxs0s2EzGz6iQ23uDkDR2gq/u+9z9wl3n5R0o6SBxLpD7t7v7v3d6mm3TwAFayv8ZtY37e5lkp4uph0AVWllqO92Saslvc3M9kj6gqTVZrZCkkvaJemTJfYIoARNw+/u62ZYfHMJvXS0rsWLGtbG16THuvc3vny8JGnRu/Yn69ede2ey/rXRNQ1rf9D3UHrnOQ307EjW84zlP/STBcn6Wfe/mqy/9tsrG9YWbn0xue3E/vS/ycmAb/gBQRF+ICjCDwRF+IGgCD8QFOEHgjJ3r2xnC63XV9qFle3vRBz+cH+y/sXrhxrW+nsmim7nDeY0+Rs9mfvk2PbN1t7uff3nktt+6bmLk/X9o+ntz7y3K1k/9a7tyXq7tvsWHfBxa2VdjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/JkzHk2fPnrD0n+pqJM3m61j6VLn9lZnX5L0W0t+tZTHZZwfQFOEHwiK8ANBEX4gKMIPBEX4gaAIPxBU00t3R3HT0n9L1idr/DvZbelzw4/k+KrG6MRPkvV/OvDuZP2m22eawPn//fz3G4+nL7jj0eS2zYx96n1tb/v2J19P1o/OT0fj4JLuZL33G4+ccE9V48gPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0E1Hec3s6WSvinpdE3NuDzk7l83s15J35K0TNIuSZe7+yvltVquSaUHy+s8/7vZOH6e3i7ctiFZP+d3n0jWl+rhtved16K/K2/f6VF8qbe0PVenlSP/UUmfc/d3Sfo1SZ82s/MkXSlpi7svl7Qluw9glmgafncfdffHs9sHJY1IWiJpraRN2WqbJF1aVpMAindC7/nNbJmkCyRtl7TY3UelqT8QkhYV3RyA8rQcfjN7q6RvS/qsux84ge0GzWzYzIaP6FA7PQIoQUvhN7NuTQX/Vnf/TrZ4n5n1ZfU+SWMzbevuQ+7e7+793eopomcABWgafjMzSTdLGnH3r04rbZa0Pru9XtI9xbcHoCytnNK7StLHJO00s2PjPldJukbSnWb2CUkvSfpIOS1W48qX05dS/tLp5UypXIQ/3TfQsLbt2pXJbX/h7qeS9XovcI0yNQ2/u2+T1Og64J15EX4ATfENPyAowg8ERfiBoAg/EBThB4Ii/EBQXLo7s/0v0+P8z17b+PTRc7vTl9Zu5vMvvzdZ33ZDurfF9+9uWFu4O315bMbx4+LIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBmXuO+Z1P0ELr9ZU2O88C7vqlcxvWJhbku0LRnKdeSNYnX09PJw0cs9236ICPNzoF/w048gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUJzP36KJZ54t7bE5px514MgPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0E1Db+ZLTWzfzWzETN7xsw+ky2/2sx+aGZPZD+/WX67AIrSypd8jkr6nLs/bmYLJO0wswez2nXufm157QEoS9Pwu/uopNHs9kEzG5G0pOzGAJTrhN7zm9kySRdI2p4t2mBmT5nZRjM7rcE2g2Y2bGbDR3QoV7MAitNy+M3srZK+Lemz7n5A0vWS3ilphaZeGXxlpu3cfcjd+929v1v5rnUHoDgthd/MujUV/Fvd/TuS5O773H3C3Scl3ShpoLw2ARStlU/7TdLNkkbc/avTlvdNW+0ySU8X3x6AsrTyaf8qSR+TtNPMnsiWXSVpnZmtkOSSdkn6ZCkdAihFK5/2b5M003XA7yu+HQBV4Rt+QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoMzdq9uZ2X5J/zNt0dsk/aiyBk5Mp/bWqX1J9NauInt7h7u/vZUVKw3/m3ZuNuzu/bU1kNCpvXVqXxK9tauu3njZDwRF+IGg6g7/UM37T+nU3jq1L4ne2lVLb7W+5wdQn7qP/ABqUkv4zewiM3vWzF4wsyvr6KERM9tlZjuzmYeHa+5lo5mNmdnT05b1mtmDZvZ89nvGadJq6q0jZm5OzCxd63PXaTNeV/6y38y6JD0naY2kPZIek7TO3f+r0kYaMLNdkvrdvfYxYTP7gKRXJX3T3c/Plv21pHF3vyb7w3mau3++Q3q7WtKrdc/cnE0o0zd9ZmlJl0r6uGp87hJ9Xa4anrc6jvwDkl5w9xfd/bCkOyStraGPjufuWyWNH7d4raRN2e1NmvrPU7kGvXUEdx9198ez2wclHZtZutbnLtFXLeoI/xJJu6fd36POmvLbJX3PzHaY2WDdzcxgcTZt+rHp0xfV3M/xms7cXKXjZpbumOeunRmvi1ZH+Gea/aeThhxWuft7JF0s6dPZy1u0pqWZm6syw8zSHaHdGa+LVkf490haOu3+mZL21tDHjNx9b/Z7TNJd6rzZh/cdmyQ1+z1Wcz8/00kzN880s7Q64LnrpBmv6wj/Y5KWm9nZZjZX0kclba6hjzcxs/nZBzEys/mSPqTOm314s6T12e31ku6psZc36JSZmxvNLK2an7tOm/G6li/5ZEMZX5PUJWmju/9F5U3MwMzO0dTRXpqaxPS2Onszs9slrdbUWV/7JH1B0t2S7pR0lqSXJH3E3Sv/4K1Bb6s19dL1ZzM3H3uPXXFv75f075J2SprMFl+lqffXtT13ib7WqYbnjW/4AUHxDT8gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0H9H2SKFBB+gaH0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize\n",
    "plt.imshow(features_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define module == single layer nn == logistic \n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, num_input, num_output):\n",
    "        super(LogisticRegression,self).__init__()\n",
    "        self.linear = nn.Linear(in_features=num_input, out_features=num_output)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "net = LogisticRegression(784,10)\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(Variable(data.next()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3363, -0.1877, -0.1123,  0.0150, -0.1622, -0.1003,  0.1452,  0.0587,\n",
       "          0.0355,  0.1783],\n",
       "        [-0.1741,  0.0177, -0.1359, -0.0289, -0.3247, -0.1134,  0.1486, -0.2022,\n",
       "          0.1117, -0.0734],\n",
       "        [ 0.1497, -0.2949, -0.2185, -0.2036, -0.1050, -0.0415,  0.1510, -0.1311,\n",
       "          0.1755,  0.1352],\n",
       "        [ 0.1923,  0.1153, -0.0880, -0.1706, -0.3295, -0.0179,  0.3001,  0.1908,\n",
       "         -0.0443,  0.2309],\n",
       "        [-0.0922,  0.0113, -0.1765, -0.0724, -0.2947, -0.0825,  0.1189, -0.0482,\n",
       "         -0.0234, -0.0532]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.3363, 0.1486, 0.1755, 0.3001, 0.1189]), tensor([0, 6, 8, 6, 6]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(out.data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, val_loss, count = [],[],0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 5, 3, 3, 6])\n",
      "tensor([4, 3, 0, 1, 6])\n",
      "1\n",
      "tensor(216, dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "vdata = iter(val_loader).next()[0]\n",
    "vdata = Variable(vdata.view(-1,28*28))\n",
    "vout = net(vdata)\n",
    "\n",
    "pred = torch.max(vout.data, 1)[1]\n",
    "print(pred)\n",
    "correct += (pred == label).sum().item()\n",
    "print(label)\n",
    "print(sum(pred==label).item())\n",
    "print(correct)\n",
    "vloss += criteria(vout,label)\n",
    "val_loss.append(vloss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epocj 0 iteration 0 vloss 0.16518250107765198 Valset accuracy 0.9171428571428571\n",
      "Epocj 0 iteration 1000 vloss 0.028889846056699753 Valset accuracy 0.914047619047619\n",
      "Epocj 0 iteration 2000 vloss 0.13660097122192383 Valset accuracy 0.9152380952380952\n",
      "Epocj 0 iteration 3000 vloss 1.6563056707382202 Valset accuracy 0.9171428571428571\n",
      "Epocj 0 iteration 4000 vloss 0.8926874995231628 Valset accuracy 0.9147619047619048\n",
      "Epocj 0 iteration 5000 vloss 0.013625621795654297 Valset accuracy 0.9176190476190477\n",
      "Epocj 0 iteration 6000 vloss 0.19921235740184784 Valset accuracy 0.9169047619047619\n",
      "Epocj 0 iteration 7000 vloss 0.06460390239953995 Valset accuracy 0.9192857142857143\n",
      "Epocj 1 iteration 0 vloss 0.26659709215164185 Valset accuracy 0.9176190476190477\n",
      "Epocj 1 iteration 1000 vloss 0.027085017412900925 Valset accuracy 0.915\n",
      "Epocj 1 iteration 2000 vloss 0.488219678401947 Valset accuracy 0.9166666666666666\n",
      "Epocj 1 iteration 3000 vloss 0.0874396339058876 Valset accuracy 0.9183333333333333\n",
      "Epocj 1 iteration 4000 vloss 0.11408348381519318 Valset accuracy 0.9180952380952381\n",
      "Epocj 1 iteration 5000 vloss 0.44612979888916016 Valset accuracy 0.9169047619047619\n",
      "Epocj 1 iteration 6000 vloss 0.043666742742061615 Valset accuracy 0.9161904761904762\n",
      "Epocj 1 iteration 7000 vloss 0.021930312737822533 Valset accuracy 0.9164285714285715\n",
      "Epocj 2 iteration 0 vloss 0.13344983756542206 Valset accuracy 0.9164285714285715\n",
      "Epocj 2 iteration 1000 vloss 0.2300311028957367 Valset accuracy 0.9178571428571428\n",
      "Epocj 2 iteration 2000 vloss 0.21051302552223206 Valset accuracy 0.92\n",
      "Epocj 2 iteration 3000 vloss 0.31971102952957153 Valset accuracy 0.9169047619047619\n",
      "Epocj 2 iteration 4000 vloss 0.08205194771289825 Valset accuracy 0.9166666666666666\n",
      "Epocj 2 iteration 5000 vloss 0.9864592552185059 Valset accuracy 0.9166666666666666\n",
      "Epocj 2 iteration 6000 vloss 0.36442965269088745 Valset accuracy 0.9169047619047619\n",
      "Epocj 2 iteration 7000 vloss 0.9691759347915649 Valset accuracy 0.9192857142857143\n",
      "Epocj 3 iteration 0 vloss 0.5534161329269409 Valset accuracy 0.9180952380952381\n",
      "Epocj 3 iteration 1000 vloss 0.08682040870189667 Valset accuracy 0.9185714285714286\n",
      "Epocj 3 iteration 2000 vloss 0.06034870073199272 Valset accuracy 0.9185714285714286\n",
      "Epocj 3 iteration 3000 vloss 0.09366340935230255 Valset accuracy 0.9188095238095239\n",
      "Epocj 3 iteration 4000 vloss 0.035574816167354584 Valset accuracy 0.9176190476190477\n",
      "Epocj 3 iteration 5000 vloss 0.23523855209350586 Valset accuracy 0.9166666666666666\n",
      "Epocj 3 iteration 6000 vloss 0.008822632022202015 Valset accuracy 0.9173809523809524\n",
      "Epocj 3 iteration 7000 vloss 0.4276343286037445 Valset accuracy 0.9176190476190477\n",
      "Epocj 4 iteration 0 vloss 0.19592872262001038 Valset accuracy 0.9204761904761904\n",
      "Epocj 4 iteration 1000 vloss 1.7474257946014404 Valset accuracy 0.9202380952380952\n",
      "Epocj 4 iteration 2000 vloss 0.322365939617157 Valset accuracy 0.9164285714285715\n",
      "Epocj 4 iteration 3000 vloss 0.10914631187915802 Valset accuracy 0.9214285714285714\n",
      "Epocj 4 iteration 4000 vloss 0.09804658591747284 Valset accuracy 0.9183333333333333\n",
      "Epocj 4 iteration 5000 vloss 0.637747585773468 Valset accuracy 0.919047619047619\n",
      "Epocj 4 iteration 6000 vloss 0.12387609481811523 Valset accuracy 0.920952380952381\n",
      "Epocj 4 iteration 7000 vloss 0.382558137178421 Valset accuracy 0.919047619047619\n",
      "Epocj 5 iteration 0 vloss 0.4694148600101471 Valset accuracy 0.9188095238095239\n",
      "Epocj 5 iteration 1000 vloss 0.11768464744091034 Valset accuracy 0.92\n",
      "Epocj 5 iteration 2000 vloss 0.7058058381080627 Valset accuracy 0.9171428571428571\n",
      "Epocj 5 iteration 3000 vloss 0.1275881826877594 Valset accuracy 0.9188095238095239\n",
      "Epocj 5 iteration 4000 vloss 0.5363739728927612 Valset accuracy 0.9223809523809524\n",
      "Epocj 5 iteration 5000 vloss 0.05777549743652344 Valset accuracy 0.9173809523809524\n",
      "Epocj 5 iteration 6000 vloss 0.040398310869932175 Valset accuracy 0.9180952380952381\n",
      "Epocj 5 iteration 7000 vloss 0.008716774173080921 Valset accuracy 0.9188095238095239\n",
      "Epocj 6 iteration 0 vloss 0.1343957930803299 Valset accuracy 0.9197619047619048\n",
      "Epocj 6 iteration 1000 vloss 0.34579771757125854 Valset accuracy 0.9188095238095239\n",
      "Epocj 6 iteration 2000 vloss 0.14824800193309784 Valset accuracy 0.9197619047619048\n",
      "Epocj 6 iteration 3000 vloss 0.12642383575439453 Valset accuracy 0.9197619047619048\n",
      "Epocj 6 iteration 4000 vloss 0.3124198019504547 Valset accuracy 0.919047619047619\n",
      "Epocj 6 iteration 5000 vloss 0.04852266237139702 Valset accuracy 0.9185714285714286\n",
      "Epocj 6 iteration 6000 vloss 0.028560161590576172 Valset accuracy 0.9192857142857143\n",
      "Epocj 6 iteration 7000 vloss 0.06166420131921768 Valset accuracy 0.9202380952380952\n",
      "Epocj 7 iteration 0 vloss 0.18297500908374786 Valset accuracy 0.9183333333333333\n",
      "Epocj 7 iteration 1000 vloss 0.16320209205150604 Valset accuracy 0.9204761904761904\n",
      "Epocj 7 iteration 2000 vloss 0.0249189380556345 Valset accuracy 0.9197619047619048\n",
      "Epocj 7 iteration 3000 vloss 0.08565673977136612 Valset accuracy 0.9195238095238095\n",
      "Epocj 7 iteration 4000 vloss 0.3123759329319 Valset accuracy 0.9185714285714286\n",
      "Epocj 7 iteration 5000 vloss 0.30976563692092896 Valset accuracy 0.9178571428571428\n",
      "Epocj 7 iteration 6000 vloss 0.04149608686566353 Valset accuracy 0.9164285714285715\n",
      "Epocj 7 iteration 7000 vloss 0.0022602081298828125 Valset accuracy 0.9207142857142857\n",
      "Epocj 8 iteration 0 vloss 0.8737770318984985 Valset accuracy 0.9214285714285714\n",
      "Epocj 8 iteration 1000 vloss 0.18619394302368164 Valset accuracy 0.9214285714285714\n",
      "Epocj 8 iteration 2000 vloss 0.03076934814453125 Valset accuracy 0.9188095238095239\n",
      "Epocj 8 iteration 3000 vloss 0.12511920928955078 Valset accuracy 0.9173809523809524\n",
      "Epocj 8 iteration 4000 vloss 0.37033718824386597 Valset accuracy 0.9197619047619048\n",
      "Epocj 8 iteration 5000 vloss 0.04413776472210884 Valset accuracy 0.9202380952380952\n",
      "Epocj 8 iteration 6000 vloss 0.0456426627933979 Valset accuracy 0.9202380952380952\n",
      "Epocj 8 iteration 7000 vloss 0.08188486099243164 Valset accuracy 0.9171428571428571\n",
      "Epocj 9 iteration 0 vloss 0.0810060054063797 Valset accuracy 0.915952380952381\n",
      "Epocj 9 iteration 1000 vloss 0.04063444212079048 Valset accuracy 0.9214285714285714\n",
      "Epocj 9 iteration 2000 vloss 0.10920801013708115 Valset accuracy 0.920952380952381\n",
      "Epocj 9 iteration 3000 vloss 0.39482125639915466 Valset accuracy 0.9180952380952381\n",
      "Epocj 9 iteration 4000 vloss 0.030388642102479935 Valset accuracy 0.920952380952381\n",
      "Epocj 9 iteration 5000 vloss 0.09523220360279083 Valset accuracy 0.9207142857142857\n",
      "Epocj 9 iteration 6000 vloss 0.5310222506523132 Valset accuracy 0.9195238095238095\n",
      "Epocj 9 iteration 7000 vloss 0.40581250190734863 Valset accuracy 0.9192857142857143\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "for e in range(epoch):\n",
    "    for i, (data, label) in enumerate(train_loader):\n",
    "\n",
    "        data = Variable(data.view(-1,28*28))\n",
    "        label = Variable(label)\n",
    "        out = net(data)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criteria(out,label)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            accuracy, correct = 0,0\n",
    "            totalvloss = 0\n",
    "            for vdata,label in val_loader:\n",
    "                vdata = Variable(vdata.view(-1,28*28))\n",
    "                vout = net(vdata)\n",
    "                label = Variable(label)\n",
    "                pred = torch.max(vout, 1)[1]\n",
    "                correct += (pred == label).sum()\n",
    "                vloss = criteria(vout,label)\n",
    "                totalvloss += vloss.item()\n",
    "            val_loss.append(totalvloss)\n",
    "\n",
    "            accuracy = (correct.item()/len(valset))\n",
    "            print('Epocj {} iteration {} vloss {} Valset accuracy {}'.format(e, i, loss.data, accuracy))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('./test.csv', dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = testdf/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Variable(torch.from_numpy(testdf.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(i.view(-1,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.max(out,1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 27997, 27998, 27999], dtype=int64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.DataFrame({'ImageId':testdf.index.values+1, 'Label': predictions.numpy()})\n",
    "newdf.to_csv('./results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
